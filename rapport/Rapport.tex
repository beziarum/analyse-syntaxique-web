\documentclass[12pt]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage{hyperref}
\usepackage{url}
\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{verbatim}
\usepackage{tocbibind}

\begin{document}
\title{Projet de programmation d'analyse syntaxique}
\author{Paul BEZIAU, Antoine BORDE, Martin BAZALGETTE}

\maketitle
\newpage
\tableofcontents
\newpage


\section{Présentation du projet}
Le projet d'analyse sintaxique consistait en la réalisation d'un compilateur
de site web qui retourne un code propre html a partir d'un code source "factice"
donné par l'énoncer.
\newline
L'énoncer proposé plusieur étape au développement permettant une avancé
pas a pas des possibilité offerte par ce code factice et de sa gestion
par le compilateur.
\newline
Le programme est composé de 3 parties différente. l'analyseur lexical (en flex) ,
l'analyseur sintaxique permettant de gérer la grammaire (en bison) et les structure
perméttant le traitement des donné et leur transformation en code html (en C).
\newline
A chacune des étapes de dévelopement il s'agissait de vérifier dans un premier
temps la qualité de la grammaire (si elle accepte se qu'elle doit et refuse
le code invalide). Et dans un second temps la bonne gestion de nos structure
et du traitement réalisé sur les donnés afin de les compilé en code html valide.

\newpage

\section{Les premiere foret}

Notre premier objectif étais d'implementer un début d'analyseur lexical et sintaxique
permettant d'accepter le premiere éxemple du code factice donné dans l'énoncer.

\subsection{les structures}

Pour commencer se projet nous nous somme penché sur la gestion des struture
"tree" et "attributes" donné par l'énoncer. Nous avons implémenté les créateurs et les
libérateurs ainsi que les accesseur et les modificateur. Rien de trés compliqué a se niveau
la la dificulté allait étre de bien tout construire au niveau de l'analyseur sintaxique.

\subsection{l'analyseur lexical}

Nous nous somme ensuite penché sur l'analyseur lexical. Nous voulions essayé de
minimisé au plus possible le traitement au niveau de flex afin que tout soit gérer
par notre gramaire dans lanalyseur sintaxique. Nous avons donc implémenter
quelque chose de trés simple qui se contente de renvoyer des token pour tout les
character ou mot que nous penssion nécessaire. Cela sans gestion d'état ou action
particuliere.

\subsection{l'analyseur sintaxique}

Nous somme ensuite ataqué a l'nalyseur sintaxique. La partie central de se projet.
Nous avons définit une suite de régle plutot simple dans un premier temps. Le but
n'etais pas encore de testé si nos arbre et nos foret s'imbriqué comme il fallait
mais simplement de vérifier que nous avions une grammaire acceptante quand c'etait
le cas et retourné une erreur le reste du temps.
\newline
Outre toute les petites difficulté classique ,due a notre manque d'expérience
sur la gestion des grammaire. Nous avons rencontré ici notre premiere
grosse dificulté.

\subsubsection{la gestion des espaces}

Les espaces étais le premier élément compliqué a gérer. il doive parfois étre accepter
d'autre fois non. Et il est dificile de gérer dans la grammaire tout ces cas de figure
Dans un premier temps nous avons définit une regle "SPACES: SPACES | %empty". Et nous
avons mis des SPACES un peu partout dans la grammaire. Mais cela a entrainer 2 probleme
le premier étais que meme si notre grammaire devenait acceptante sur les bon fichier
elle l'étais aussi a des moment ou elle n'aurait pas du l'étre. le deuxieme étais un
nombre phénoménal de conflit reduction/réduction (+ de 50).
\newline
Nous avons donc décider aprés réfléxion de nous résoudre a compléxifier le code lex
afin d'éffectuer un poste traitement sur les espace a accepter ou non.
Nous avons définit un etat ainsi qu'une variable "lastIsSpace" charger de mémorisé
si les dernier charactere etais des espaces. Cela nous a permit de ne retourné les
espace que quand cela étais vraiment necessaire et d'énormement simplifier la grammaire.
Nous avons alors réussi a obtenir une grammaire convainquante.



\newpage

\section{Le compilateur}

Notre programme commencant a reconaitre les premier élément de sintaxe
du code donné par l'énoncer nous nous somme lancé sur la réalisation de notre
premiere vrais compilation.
\newline
\newline
Mais nous avons alors été confronté au changemen de sujet concernant les structures
et leur implementations.

\subsection{Changement total des structure}

Le sujet a donc proposé une nouvelle implémentation des structure (deja au point) afin de nous
permettre de nous concentré essentielement sur l'analyse sintaxique(qui est effectivement
le veritable objectif de cette UE). Mais il était cependant parfois difficile de comprendre
le fonctionnement de se code, et de bien gérer les structure pour quelle gére les donnée
de la maniere attendu. La gestion des structure resté donc un probleme difficile
a gérer.

\subsection{la fonction emit}

L'implementation donné par le sujet n'étais pas encore tout a fait complete.
Il resté nottament a implémenté la fonction emit qui devait se charger de recupéré
notre arborescence de structure pour réecrire les donnée sous la forme d'un code
html valide dans un fichier.
\newline
\newline
Si une fois les nouvelle structure comprise l'écriture des balises n'etais pas
d'une grande difficulté. La gestion des indentation et des retour a la ligne
étais quand a elle plus complexe. Nous avons dans un premier temps opté pour
une fonction recursive qui intégre dans ces parametre une variable indiquant
le nombre d'indentation a éffectuer. Nous retournons également un boolean qui
nous aide a déterminé celon les cas si le retour a la ligne est necessaire ou pas.
\newline
a se stade le resultat n'etais pas parfait mais convainquant et sufisament claire
pour commencer les test.


\subsection{les premieres compilation}

Des les premiere tentative.

\newpage

\section{Conclusion}
c'était cool




\end{document}
\grid
