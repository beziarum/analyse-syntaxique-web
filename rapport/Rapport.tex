\documentclass[12pt]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage{hyperref}
\usepackage{url}
\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{verbatim}
\usepackage{tocbibind}

\begin{document}
\title{Projet de programmation d'analyse syntaxique}
\author{Paul BEZIAU, Antoine BORDE, Martin BAZALGETTE}

\maketitle
\newpage
\tableofcontents
\newpage


\section{Présentation du projet}
Le projet d'analyse syntaxique consistait en la réalisation d'un compilateur
de site web qui retourne un code html propre à partir d'un code source "factice"
donné par l'énoncé.
\newline
L'énoncé proposait plusieurs étapes au développement permettant une avancée
pas à pas des possibilités offertes par ce code factice et de sa gestion
par le compilateur.
\newline
Le programme est composé de 3 parties différentes. l'analyseur lexical (en langage flex) ,
l'analyseur syntaxique permettant de gérer la grammaire (en langage bison) et les structures
permettant le traitement des données et leur transformation en code html (en langage C).
\newline
A chacune des étapes de dévelopement, il s'agissait de vérifier dans un premier
temps la qualité de la grammaire (si elle accepte ce qu'elle doit et refuse
le code invalide), et dans un second temps la bonne gestion de nos structures
et du traitement réalisé sur les données afin de les compiler en code html valide.

\newpage

\section{Les premieres forêts}

Notre premier objectif était d'implementer un début d'analyseur lexical et syntaxique
permettant d'accepter le premiere éxemple du code factice donné dans l'énoncé.

\subsection{Les structures}

Pour commencer ce projet, nous nous somme penchés sur la gestion des strutures
"tree" et "attributes" données par l'énoncé. Nous avons implémenté les créateurs et les
libérateurs ainsi que les accesseurs et les modificateurs. Rien de très compliqué a ce niveau
là, la dificulté était de bien tout construire au niveau de l'analyseur syntaxique.

\subsection{L'analyseur lexical}

Nous nous somme ensuite penchés sur l'analyseur lexical. Nous voulions essayer de
minimiser le plus possible le traitement au niveau de flex afin que tout soit géré
par notre grammaire dans l'analyseur syntaxique. Nous avons donc implémenté
quelque chose de très simple qui se contente de renvoyer des tokens pour tous les
characters ou mots que nous pensions nécessaires. Cela sans gestion d'états ou actions
particulières.

\subsection{L'analyseur syntaxique}

Nous somme ensuite ataqués à l'analyseur syntaxique, la partie centrale de ce projet.
Nous avons défini une suite de règles plutôt simples dans un premier temps. Le but
n'etait pas encore de tester si nos arbres et nos forêts s'imbriquaient comme il fallait,
mais simplement de vérifier que nous avions une grammaire acceptante quand c'etait
le cas et de retourner une erreur le reste du temps.
\newline
Outre toutes les petites difficultés classiques dues à notre manque d'expérience
sur la gestion des grammaires, Nous avons rencontré ici notre première
grosse dificulté.

\subsubsection{La gestion des espaces}

Les espaces représentaient le premier élément compliqué à gérer. il doivent parfois étre acceptés,
d'autres fois non. Il est difficile de gérer dans la grammaire tous ces cas de figure.
Dans un premier temps, nous avons défini une regle "SPACES: SPACES | %empty", et nous
avons mis des SPACES un peu partout dans la grammaire. Mais celà entrainait 2 problèmes :
le premier était que même si notre grammaire devenait acceptante sur les bons fichiers,
elle l'était aussi à des moments où elle n'aurait pas du l'être. Le deuxième était un
nombre phénoménal de conflits reduction/réduction (+ de 50).
\newline
Nous avons donc décidé après réfléxion de nous résoudre a complexifier le code lex
afin d'éffectuer un prés traitement sur les espaces à accepter ou non.
Nous avons défini un état ainsi qu'une variable "lastIsSpace" chargée de mémoriser
si les derniers caractères etaient des espaces. Celà nous a permi de ne retourner des token
différent quand il été précéder d'un espace et ainsi d'énormement simplifier la grammaire.
Nous avons alors réussi a obtenir une grammaire satisfaisante.



\newpage

\section{Le compilateur}

Notre programme commencant a reconaitre les premier élément de sintaxe
du code donné par l'énoncer nous nous somme lancé sur la réalisation de notre
premiere vrais compilation.
\newline
\newline
Mais nous avons alors été confronté au changemen de sujet concernant les structures
et leur implementations.

\subsection{Changement total des structure}

Le sujet a donc proposé une nouvelle implémentation des structure (deja au point) afin de nous
permettre de nous concentré essentielement sur l'analyse sintaxique(qui est effectivement
le veritable objectif de cette UE). Mais il était cependant parfois difficile de comprendre
le fonctionnement de se code, et de bien gérer les structure pour quelle gére les donnée
de la maniere attendu. La gestion des structure resté donc un probleme difficile
a gérer.

\subsection{la fonction emit}

L'implementation donné par le sujet n'étais pas encore tout a fait complete.
Il resté nottament a implémenté la fonction emit qui devait se charger de recupéré
notre arborescence de structure pour réecrire les donnée sous la forme d'un code
html valide dans un fichier.
\newline
\newline
Si une fois les nouvelle structure comprise l'écriture des balises n'etais pas
d'une grande difficulté. La gestion des indentation et des retour a la ligne
étais quand a elle plus complexe. Nous avons dans un premier temps opté pour
une fonction recursive qui intégre dans ces parametre une variable indiquant
le nombre d'indentation a éffectuer. Nous retournons également un boolean qui
nous aide a déterminé celon les cas si le retour a la ligne est necessaire ou pas.
\newline
a se stade le resultat n'etais pas parfait mais convainquant et sufisament claire
pour commencer les test.


\subsection{les premieres compilation}

Des les premieres tentative. Nous avons eu de nombreuse erreur du a la mauvaise
gestion des structures. Nous n'avions nottament pas compris comment chainer
les mots. Nous avons décidé de les considérer comme des foret qui s'empile les
une aprés les autre jusqua se que tout les mot de la chaine soit insérer.
Aprés quelque ajustement et correction nous avons obtenue un programme qui
compiler correctement le code factice dans sa version simple.(gestion des noeud,
des attribut et de l'operateur emit).

\newpage


\section{enrichisement de la sintaxe}

\subsection{les variables}



\section{Conclusion}
c'était cool




\end{document}
\grid
